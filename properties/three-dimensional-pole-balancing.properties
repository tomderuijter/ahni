# Reproduces the Markovian double pole balancing task (with velocities included in inputs) as described in:
# Stanley, K. O. and Miikkulainen, R. (2002). Evolving neural networks through augmenting topologies. Evolutionary Computation, 10 (2), 99-127.

#random.seed=1234567
run.name=tdpb
run.reset=true

# If set to "true" then substitutions present in property values will be enabled. Substitutions have the format $([key]), where [key] is the key of another property.
substitution.enable=true

###########
# evolution
###########

num.runs=1
num.generations=500
popul.size=1000

performance.target=1.0
performance.target.type=higher
# If greater than 1 then use an average of the best performance over this many generations.
performance.target.average=1

#false means mutation probabilities are applied to all possible places a mutation could occur
#true means probabilities apply to individual as a whole; only one topological mutation can occur per individual
#note that this applies only to topological mutations, not weight mutations
topology.mutation.classic=true

#[0.01, 0.5]
add.neuron.mutation.rate=0.03

# Mutation rate for operator that adds neurons anywhere in the network (as 
# opposed to regular add neuron operator that only adds them in place of 
# existing connections). Only works for topology.mutation.classic=false
add.neuron.anywhere.mutation.rate=0.0

#[0.01, 0.5]
add.connection.mutation.rate=0.3
#[0.01, 0.3]
remove.connection.mutation.rate=0.01
#only remove weights with magnitude smaller than this
remove.connection.max.weight=100

#[0.1, 0.8]
weight.mutation.rate=0.8
#[1.0, 2.0] dependent on (CPPN) weight.max/min?
weight.mutation.std.dev=1
# The amount to perturb weights by when generating the initial population. Default is weight.mutation.std.dev
#weight.mutation.std.dev.initial=0.01

#percent of individuals used as parents
survival.rate=0.4
#proportion of sexual (crossover) versus asexual reproduction.
crossover.proportion=0.75
# the probability that an individual produced by the crossover operator will be a candidate for having mutations applied to it (independent of other mutation probabilities).
crossover.mutate.probability=0.8

#[1, 5]
#selector.elitism.min.specie.size=5
selector.elitism.min.specie.size=0
#percent of individuals from each species copied to next generation unchanged
#selector.elitism.proportion=0.0
selector.elitism.proportion=0.1
#min number to select from a species (if it has size >=  selector.elitism.min.specie.size), default is the number of objectives defined by the fitness function.
#selector.elitism.min.to.select=1
selector.elitism.min.to.select=0
# The NaturalSelector to use to perform the parent (and elite) selection. Default is com.anji.integration.SimpleSelector.
#selector.class=com.ojcoleman.ahni.misc.NSGAIISelector
selector.min.generations=0
selector.max.stagnant.generations=1000000
selector.speciated.fitness=true


############
# speciation
############
#species distance factors
#c1, excess genes factor [1.0, 2.0]
chrom.compat.excess.coeff=1
#c2, disjoint genes factor [1.0, 2.0]
chrom.compat.disjoint.coeff=1
#c3, Weight difference factor [0.2, 3.0]
#chrom.compat.common.coeff=0.4
chrom.compat.common.coeff=1

# initial compatibility threshold [0.1, 4.0], relative to c#
speciation.threshold=3
# Target number of species, default is popul.size ^ 0.55 (bit more than square root)
#speciation.target=10


##################
# fitness function
##################
fitness_function.class=com.ojcoleman.ahni.experiments.polebalancing.TwoDimPoleBalancing
fitness.function.performance.force.fitness = true
#max threads to use for fitness evaluation (including transcription of genotype/cppn to phenotype/substrate)
#if value is <= 0 then the detected number of processor cores will be used
fitness.max_threads=0

##########################
# Experiment Configuration 
##########################
fitness.environment.trackLength=4.8
fitness.environment.gravity=-9.8

fitness.simulation.maxTimeSteps=100000
fitness.simulation.poleAngleThreshold=0.62831853071
# 36 degrees expressed in radians
fitness.simulation.includeVelocity=false

fitness.agent.cartMass=1
fitness.agent.cartFriction=0
fitness.agent.poleCount=1
# Mass and length are only specified for the first pole.
# For any next poles, length is decreased by a constant 
# factor, with its mass and friction adjusted proportionally.
fitness.agent.poleMass=0.1
fitness.agent.poleLength=0.5
fitness.agent.poleFriction=0.000002

fitness.agent.initial.cartPositionX=0
fitness.agent.initial.cartPositionY=0
fitness.agent.initial.cartVelocityX=0
fitness.agent.initial.cartVelocityY=0
fitness.agent.initial.poleAngle=0.0698131701
# Four degree deviation from vertical position. 
# Only applies to first pole.
fitness.agent.initial.poleVelocity=0

################
# CPPN/AnjiNet #
################

# Network input size
# 4 + (4 * poleCount) including velocity
# 2 + (2 * poleCount) excluding velocity
stimulus.size=4
# Network output size
response.size=2

# Network initialization
# The type of activation function to use in the CPPN, "random" means a function will be randomly picked.
initial.topology.activation=sigmoid-steep
# The activation function types that may be added to the CPPN if initial.topology.activation=random.
# initial.topology.activation.random.allowed=sigmoid, gaussian, sine, absolute

# if initial.topology.fully.connected=false then the initial population will be generated by applying the mutation operators to clones of the 
# sample chromosome (which will just contain the input and output neurons and optionally some hidden neurons (see initial.topology.num.hidden.neurons)).
# The mutation rates of the operators may be temporarily increased during this process by setting initial.topology.mutation.factor to a value greater than 1.
initial.topology.fully.connected=true
# Mutation factor for generating initial population
initial.topology.mutation.factor=50
# Size of neurons in single hidden layer
initial.topology.num.hidden.neurons=0

initial.topology.activation.input=linear
initial.topology.activation.output=sigmoid-steep
#initial.topology.activation.random.allowed=sigmoid-steep, sine, linear
bias.via.input=true

#recurrent=disallowed
recurrent=best_guess
recurrent.cycles=1
#[1, 500]
# Set to 3 as this is the magnitude for one connection receiving an input of 1 to drive a (bipolar-)sigmoid or gaussian to saturation.
weight.min=-20
weight.max=20

# Network type used for transcribing
ann.transcriber.class=com.anji.integration.AnjiNetTranscriber

#############
# persistence
#############
persistence.class=com.anji.persistence.FilePersistence
persistence.base.dir=./db/$(run.name)
persist.enable=true
persist.all=false
persist.champions=true
# Persist champions of each generation
persist.last=false
# Persist entire population of last generation
persist.load.genotype=true
id.file=./db/$(run.name)/id.xml
neat.id.file=./db/$(run.name)/neatid.xml

##############
# presentation
##############
presentation.dir=./presentation/$(run.name)
presentation.generate=false

#########
# logging
#########
output.dir=./temp/$(run.name)
# How often to produce a line in the log containing a brief summary of the current progress.
log.pergenerations=1
# Whether to log the champ to a text file and/or image. N < 0 indicates no logging, N=0 indicates 
# only at the end of evolution, N > 0 indicates every N generations and after evolution has finished.
log.champ.tostring=50
log.champ.toimage=50
#log.selector.nsgaii=true


# FileAppenders with the name RunLog receive special treatment: for each run the output will be directed to a file 
# with the name specified by log4j.appender.RunLog.File in the directory [output.dir]/[run number]/
log4j.rootLogger=INFO, C, RunLog
log4j.appender.C=org.apache.log4j.ConsoleAppender
log4j.appender.RunLog=org.apache.log4j.FileAppender
log4j.appender.RunLog.File=log.txt
log4j.appender.C.layout=org.apache.log4j.PatternLayout
log4j.appender.RunLog.layout=org.apache.log4j.PatternLayout
log4j.appender.C.layout.ConversionPattern=%-5p %m%x%n
log4j.appender.RunLog.layout.ConversionPattern=%-5p %m%x%n



#####################################
# parameter tuning via ParameterTuner #
#######################################

#parametertuner.totune=       ann.hyperneat.includeangle, ann.hyperneat.cyclesperstep, ann.hyperneat.leo.threshold.factordistance, weight.max, fitness.function.novelty.k, ann.transcriber.connection.weight.max, weight.mutation.rate, weight.mutation.std.dev, add.connection.mutation.rate, add.neuron.anywhere.mutation.rate
#parametertuner.types=	     b,                          i,                           b,                                          d,          i,                          d,                                     d,                    d,                       d,                            d
#parametertuner.initialvalues=0,                          3,                           0,                                          3,          30,                         10,                                    0.2,                  0.2,                     1.0,                          0.015
#parametertuner.minvalues=    0,                          1,                           0,                                          0,          1,                          0,                                     0,                    0,                       0,                            0
#parametertuner.maxvalues=    1,                          1000,                        1,                                          1000,       1000,                       1000,                                  1,                    1000,                    1000,                         1000
#parametertuner.initialvalueadjustfactor=2
#parametertuner.numruns=1
#parametertuner.numgens=500
#parametertuner.solvedperformance=0.98
#parametertuner.htcondor=\
#  Rank                  = kflops \n \
#  +RequiresWholeMachine = True \n \
#  notification = Never
